Model: ./LlamaBase, Output Type: vanilla, Size: 1
CodeBleu Score: 0.3041014537916487
Rouge-L score: {'r': 0.2903392681198288, 'p': 0.14994150154205735, 'f': 0.16674280982494827}
BertScore: r: 0.8297707438468933, p: 0.7693343758583069, f: 0.797082245349884
--------------------------------------------------------------------------------
Model: ./Llama2b, Output Type: vanilla, Size: 1
CodeBleu Score: 0.2963937156214164
Rouge-L score: {'r': 0.2414191384952439, 'p': 0.13628212244328577, 'f': 0.15418514906850145}
BertScore: r: 0.8228551745414734, p: 0.7836917638778687, f: 0.8025518655776978
--------------------------------------------------------------------------------
Model: ./Llama2c, Output Type: vanilla, Size: 1
CodeBleu Score: 0.33736256230551054
Rouge-L score: {'r': 0.27682509003218625, 'p': 0.15211429075989838, 'f': 0.17728725396859915}
BertScore: r: 0.8363308906555176, p: 0.7799477577209473, f: 0.8066778182983398
--------------------------------------------------------------------------------
